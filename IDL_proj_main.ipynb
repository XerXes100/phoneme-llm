{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ZuIeN7Wz60AA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://drive.google.com/file/d/1c2YtIaJkMPGZkSStlzgU-2UzZf3J0K13/view?usp=sharing"
      ],
      "metadata": {
        "id": "O6EHIVHuvTrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ! gdown --id 1c2YtIaJkMPGZkSStlzgU-2UzZf3J0K13"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0dOnxjzsI1l",
        "outputId": "358940cf-bea1-4f9f-8f83-667fb7d18680"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1c2YtIaJkMPGZkSStlzgU-2UzZf3J0K13\n",
            "To: /content/DS_10283_3443_mini.zip\n",
            "100% 309M/309M [00:03<00:00, 83.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install transformers datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N01Fh9UTYqrG",
        "outputId": "afbe9129-c840-461a-86fb-94f45490069b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install phonemizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qXtTiAPYsTd",
        "outputId": "0d147e96-c59a-4d85-84d3-086b20b75c4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: phonemizer in /usr/local/lib/python3.10/dist-packages (3.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from phonemizer) (1.3.2)\n",
            "Requirement already satisfied: segments in /usr/local/lib/python3.10/dist-packages (from phonemizer) (2.2.1)\n",
            "Requirement already satisfied: attrs>=18.1 in /usr/local/lib/python3.10/dist-packages (from phonemizer) (23.1.0)\n",
            "Requirement already satisfied: dlinfo in /usr/local/lib/python3.10/dist-packages (from phonemizer) (1.2.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from phonemizer) (4.5.0)\n",
            "Requirement already satisfied: clldutils>=1.7.3 in /usr/local/lib/python3.10/dist-packages (from segments->phonemizer) (3.20.0)\n",
            "Requirement already satisfied: csvw>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from segments->phonemizer) (3.2.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from segments->phonemizer) (2023.6.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from clldutils>=1.7.3->segments->phonemizer) (2.8.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from clldutils>=1.7.3->segments->phonemizer) (0.9.0)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from clldutils>=1.7.3->segments->phonemizer) (6.7.0)\n",
            "Requirement already satisfied: pylatexenc in /usr/local/lib/python3.10/dist-packages (from clldutils>=1.7.3->segments->phonemizer) (2.10)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from clldutils>=1.7.3->segments->phonemizer) (3.4.4)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from clldutils>=1.7.3->segments->phonemizer) (4.9.3)\n",
            "Requirement already satisfied: markupsafe in /usr/local/lib/python3.10/dist-packages (from clldutils>=1.7.3->segments->phonemizer) (2.1.3)\n",
            "Requirement already satisfied: babel in /usr/local/lib/python3.10/dist-packages (from csvw>=1.5.6->segments->phonemizer) (2.12.1)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from csvw>=1.5.6->segments->phonemizer) (0.4.6)\n",
            "Requirement already satisfied: isodate in /usr/local/lib/python3.10/dist-packages (from csvw>=1.5.6->segments->phonemizer) (0.6.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from csvw>=1.5.6->segments->phonemizer) (4.19.0)\n",
            "Requirement already satisfied: language-tags in /usr/local/lib/python3.10/dist-packages (from csvw>=1.5.6->segments->phonemizer) (1.2.0)\n",
            "Requirement already satisfied: rdflib in /usr/local/lib/python3.10/dist-packages (from csvw>=1.5.6->segments->phonemizer) (7.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from csvw>=1.5.6->segments->phonemizer) (2.31.0)\n",
            "Requirement already satisfied: rfc3986<2 in /usr/local/lib/python3.10/dist-packages (from csvw>=1.5.6->segments->phonemizer) (1.5.0)\n",
            "Requirement already satisfied: uritemplate>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from csvw>=1.5.6->segments->phonemizer) (4.1.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from isodate->csvw>=1.5.6->segments->phonemizer) (1.16.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->csvw>=1.5.6->segments->phonemizer) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->csvw>=1.5.6->segments->phonemizer) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->csvw>=1.5.6->segments->phonemizer) (0.10.2)\n",
            "Requirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from rdflib->csvw>=1.5.6->segments->phonemizer) (3.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->csvw>=1.5.6->segments->phonemizer) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->csvw>=1.5.6->segments->phonemizer) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->csvw>=1.5.6->segments->phonemizer) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->csvw>=1.5.6->segments->phonemizer) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !sudo apt-get update\n",
        "# !sudo apt-get install espeak"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmUu5emaYugx",
        "outputId": "13ce60ed-70cc-4362-8068-d126de2024b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:2 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "espeak is already the newest version (1.48.15+dfsg-3).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 129 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install g2p-en"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OrYUffMq2JE",
        "outputId": "4a2fed72-8a75-4007-8a76-8b8986bd7386"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: g2p-en in /usr/local/lib/python3.10/dist-packages (2.1.0)\n",
            "Requirement already satisfied: numpy>=1.13.1 in /usr/local/lib/python3.10/dist-packages (from g2p-en) (1.23.5)\n",
            "Requirement already satisfied: nltk>=3.2.4 in /usr/local/lib/python3.10/dist-packages (from g2p-en) (3.8.1)\n",
            "Requirement already satisfied: inflect>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from g2p-en) (7.0.0)\n",
            "Requirement already satisfied: distance>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from g2p-en) (0.1.3)\n",
            "Requirement already satisfied: pydantic>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from inflect>=0.3.1->g2p-en) (1.10.12)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from inflect>=0.3.1->g2p-en) (4.5.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.4->g2p-en) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.4->g2p-en) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.4->g2p-en) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.4->g2p-en) (4.66.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install wget  # Install wget if not already installed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Zph1jHW1kqf",
        "outputId": "1fedf357-7ee7-4629-9a0b-395d558d07ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=72f8d8a52b239a9549dc62fcafaa00252fc71dfa2f9eec7d5e5229f219d5e553\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wget"
      ],
      "metadata": {
        "id": "eBcV1UUeKvRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Provide the URL of the dataset file you want to download\n",
        "url = 'https://datashare.ed.ac.uk/download/DS_10283_3443.zip'  # Replace with your dataset URL\n",
        "\n",
        "# Download the dataset file to the current directory in Colab\n",
        "wget.download(url)\n",
        "print(\"Download success!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsq4QVlG1lF1",
        "outputId": "e2d79f88-01c6-457d-c19f-142b2a2f1073"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download success!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "from collections import defaultdict\n",
        "from IPython.display import Audio, display\n",
        "import torch\n",
        "import torchaudio\n",
        "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "import csv\n",
        "import torch\n",
        "from g2p_en import G2p\n",
        "import re\n",
        "import string\n",
        "import tqdm"
      ],
      "metadata": {
        "id": "oNTSbD7-Z3ja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XI9KlPBhteRV",
        "outputId": "5e617491-cffe-4c78-82ac-df82083953ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace 'filename.zip' with the name of your uploaded zip file\n",
        "zip_ref = zipfile.ZipFile('/content/VCTK-Corpus-0.92.zip', 'r')\n",
        "zip_ref.extractall('/content')  # Specify the folder to extract to\n",
        "zip_ref.close()\n"
      ],
      "metadata": {
        "id": "B1peuI6olPHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Base directory\n",
        "base_dir = '/content/VCTK-Corpus-0.92'  # Replace with your base directory path\n",
        "\n",
        "# Directories for text and wav files\n",
        "text_dir = os.path.join(base_dir, 'txt')\n",
        "wav_dir = os.path.join(base_dir, 'wav48_silence_trimmed')\n",
        "\n",
        "# Initialize a defaultdict to store mappings\n",
        "file_mapping = defaultdict(list)\n",
        "\n",
        "# Function to extract file names without extensions\n",
        "def get_filename(file_path):\n",
        "    return os.path.splitext(os.path.basename(file_path))[0]\n",
        "\n",
        "# Traverse through text directory\n",
        "for root, dirs, files in os.walk(text_dir):\n",
        "    for file in files:\n",
        "        if file.endswith('.txt'):  # Assuming text files end with .txt\n",
        "            text_file_path = os.path.join(root, file)\n",
        "            text_prefix = get_filename(text_file_path)\n",
        "\n",
        "            # Find mic1 files corresponding to each text file\n",
        "            wav_speaker_dir = os.path.join(wav_dir, os.path.basename(os.path.dirname(text_file_path)))\n",
        "            if os.path.exists(wav_speaker_dir):\n",
        "                wav_files = os.listdir(wav_speaker_dir)\n",
        "                for wav_file in wav_files:\n",
        "                    if wav_file.startswith(text_prefix) and wav_file.endswith('_mic1.flac'):\n",
        "                        mic1_file_path = os.path.join(wav_speaker_dir, wav_file)\n",
        "                        file_mapping[text_file_path].append(mic1_file_path)\n"
      ],
      "metadata": {
        "id": "tlFDUMGsmhd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = {'audio_file': [], 'ground_truth':[]}\n",
        "\n",
        "# Play FLAC audio and display text\n",
        "for key, value in file_mapping.items():\n",
        "    for text_path, mic1_path in zip([key]*len(value), value):\n",
        "        data['audio_file'].append(mic1_path)\n",
        "        with open(text_path, 'r') as file:\n",
        "            text_content = file.read()\n",
        "            data['ground_truth'].append(text_content)\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df.to_csv('mini_vctk_transcipts.csv', index=True)"
      ],
      "metadata": {
        "id": "x5SDBSo_g4f-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TulCcvqJTtxn"
      },
      "source": [
        "## Preparation\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccfQTtHQTtxn",
        "outputId": "eabc99fb-aeb6-4778-817c-477bcca160d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-lv-60-espeak-cv-ft\")\n",
        "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-lv-60-espeak-cv-ft\")\n",
        "\n",
        "def resample_audio(file_path, target_sample_rate=16000):\n",
        "    # Load the audio file\n",
        "    waveform, original_sample_rate = torchaudio.load(file_path)\n",
        "\n",
        "    # Check if the audio needs to be resampled\n",
        "    if original_sample_rate != target_sample_rate:\n",
        "        resampler = torchaudio.transforms.Resample(orig_freq=original_sample_rate, new_freq=target_sample_rate)\n",
        "        waveform = resampler(waveform)\n",
        "\n",
        "    return waveform, target_sample_rate\n",
        "def speech_to_phonemes(file_path):\n",
        "    # Load audio\n",
        "    speech_array, sampling_rate = resample_audio(file_path)\n",
        "    speech_array = speech_array.squeeze()\n",
        "\n",
        "    # Process audio\n",
        "    inputs = processor(speech_array, sampling_rate=sampling_rate, return_tensors=\"pt\", padding=True)\n",
        "\n",
        "    # Forward pass through the model\n",
        "    with torch.no_grad():\n",
        "        logits = model(inputs.input_values).logits\n",
        "\n",
        "    # Decode the predicted IDs to phonemes\n",
        "    predicted_ids = torch.argmax(logits, dim=-1)\n",
        "    phonemes = processor.batch_decode(predicted_ids)\n",
        "\n",
        "    return phonemes\n",
        "# IPA to ARPABET mapping for vowels\n",
        "ipa_to_arpabet_vowels = {\n",
        "    'ɑ': 'AA',     # father, start\n",
        "    'æ': 'AE',     # bat\n",
        "    'ʌ': 'AH',     # butt\n",
        "    'ɔ': 'AO',     # caught, talk\n",
        "    'aʊ': 'AW',    # bout\n",
        "    'ə': 'AX',     # about, syrup [1]\n",
        "    'ər': 'AXR',   # letter, perceive [3]\n",
        "    'eɪ': 'EY',    # bait\n",
        "    'ɛ': 'EH',     # bet\n",
        "    'ɝ': 'ER',     # bird, nurse\n",
        "    'ɪ': 'IH',     # bit\n",
        "    'i': 'IY',     # beat\n",
        "    'aɪ': 'AY',    # bite\n",
        "    'ɑr': 'AA R',  # barn, star [2]\n",
        "    'ɔɪ': 'OY',    # boy\n",
        "    'oʊ': 'OW',    # boat\n",
        "    'u': 'UW',     # boot\n",
        "    'ʊ': 'UH',     # book\n",
        "}\n",
        "\n",
        "# IPA to ARPABET mapping for consonants\n",
        "ipa_to_arpabet_consonants = {\n",
        "    'b': 'B',      # buy\n",
        "    'tʃ': 'CH',    # China\n",
        "    'd': 'D',      # die\n",
        "    'ð': 'DH',     # thy\n",
        "    'f': 'F',      # fight\n",
        "    'ɡ': 'G',      # guy\n",
        "    'h': 'HH',     # high\n",
        "    'dʒ': 'JH',    # jive\n",
        "    'k': 'K',      # kite\n",
        "    'l': 'L',      # lie\n",
        "    'm': 'M',      # my\n",
        "    'n': 'N',      # nigh\n",
        "    'ŋ': 'NG',     # sing, finger\n",
        "    'ɲ': 'NX',     # canyon [3]\n",
        "    'p': 'P',      # pie\n",
        "    'ɹ': 'R',      # rye\n",
        "    's': 'S',      # sigh\n",
        "    'ʃ': 'SH',     # shy\n",
        "    't': 'T',      # tie\n",
        "    'θ': 'TH',     # thigh\n",
        "    'v': 'V',      # vie\n",
        "    'w': 'W',      # wise\n",
        "    'ʍ': 'WH',     # which [without wine–whine merger]\n",
        "    'j': 'Y',      # yacht\n",
        "    'z': 'Z',      # zoo\n",
        "    'ʒ': 'ZH',     # pleasure\n",
        "}\n",
        "\n",
        "# Merge both dictionaries into one\n",
        "ipa_to_arpabet = {**ipa_to_arpabet_vowels, **ipa_to_arpabet_consonants}\n",
        "\n",
        "# Example usage of the mapping\n",
        "def convert_ipa_to_arpabet(ipa_transcription):\n",
        "    # Split the transcription into individual phonemes\n",
        "    # Note: for affricates and diphthongs, use a more sophisticated parsing technique\n",
        "    # that recognizes multi-character IPA symbols.\n",
        "    arpabet_transcription = [ipa_to_arpabet.get(phoneme, '') for phoneme in ipa_transcription.split()]\n",
        "    return ' '.join(arpabet_transcription)\n",
        "\n",
        "def clean_string(input_string):\n",
        "    # Remove integers\n",
        "    result = re.sub(r'\\d+', '', input_string)\n",
        "    # Remove punctuation\n",
        "    result = result.translate(str.maketrans('', '', string.punctuation))\n",
        "    # Remove trailing spaces\n",
        "    result = result.strip()\n",
        "    return result"
      ],
      "metadata": {
        "id": "16aPXutxrGXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/mini_vctk_transcipts.csv')\n",
        "df['audio_phonetics'] = None\n",
        "df['audio_phonemes'] = None\n",
        "df['gt_phonemes'] = None\n",
        "\n",
        "\n",
        "g2p = G2p()\n",
        "\n",
        "for i in tqdm.tqdm(range(len(df))):\n",
        "  df.loc[i, 'audio_phonetics'] = list(speech_to_phonemes(df.loc[i, 'audio_file']))\n",
        "  df.loc[i, 'audio_phonemes'] = convert_ipa_to_arpabet(df.loc[i, 'audio_phonetics'][0])\n",
        "  df.loc[i, 'gt_phonemes'] = ' '.join(g2p(df.loc[i, 'ground_truth']))\n",
        "  df.loc[i, 'gt_phonemes'] = clean_string(df.loc[i, 'gt_phonemes'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4tIxWLHs_92",
        "outputId": "8455825c-4a06-4420-9874-6d2ca9d23f04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44283/44283 [11:03:46<00:00,  1.11it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('/content/mini_vctk_p_to_p.csv', index=False)"
      ],
      "metadata": {
        "id": "ir2hWCh2z9P6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accent_df = pd.read_csv(\"/content/idl_speakers_accent_main.csv\")"
      ],
      "metadata": {
        "id": "-4mm7eCkNLkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_paths = df['audio_file'].str.split('/')\n",
        "df['ID'] = split_paths.apply(lambda x: x[-2])\n",
        "\n",
        "accent_df['ID'] = accent_df['ID'].astype(str)\n",
        "\n",
        "df = pd.merge(df, accent_df, on='ID')\n",
        "df = df[['ID', 'ACCENTS', 'audio_file', 'ground_truth', 'audio_phonetics', 'audio_phonemes', 'gt_phonemes']]"
      ],
      "metadata": {
        "id": "A7jgm6tBNMvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('/content/vctk_with_accent.csv', index=False)"
      ],
      "metadata": {
        "id": "DJKlxnsFN79d"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}